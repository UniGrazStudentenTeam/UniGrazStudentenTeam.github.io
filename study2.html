<!DOCTYPE HTML>
<!--
	Directive by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Directive by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
		<a href="index.html" class="button">Home</a>

	<body class="is-preload">

			<!-- Header -->
			<div id="header">
				<span class="logo icon solid fa-user-friends"></span>
				<h1>Wearables in Social Sensing</h1>
				<p>Short Overview 
				<br />
				</p>
			</div>

			<div id="main">
		<!-- Main -->


				<div class="box container">

					<header>
						<h2>Wearable Social Sensing: Content-Based Processing Methodology and Implementation</h2>
					</header>
					<br><br>
					<section>	
					<button class="accordion">What was done?</button>
					<div class="panel">
					  	<p>The study involved the <b>development</b> of a wearable device designed to discreetly capture behavioral 
							and contextual details, aimed at providing cues for the onset of <b>anxiety</b>.</p>
					</div> 
					<br><br>
		
					<button class="accordion">What were the results?</button>
					<div class="panel">
						<p>The main accomplishments of the study include the successful development of a novel device capable of <b>speech</b> 
							and <b>motion tracking</b> while being subtly wrist worn. The implementation of <b>embedded speech processing</b> eliminates 
							the need to record raw audio. It was observed that when individuals spoke English (not their main language),
							 their <b>body movements</b> exhibited a <b>stronger</b> correlation with anxiety, likely due to the body's involvement 
							 compensating for a lack of verbal communication skills. Additionally, it was noted that the <b>activity</b> of the 
							 right hand (mostly dominant hand) more prominently reflected inner <b>anxiety states</b>. The study also found that
							  specific speech features (brightness_sp and MFCC5_sp) demonstrated a <b>72.73% accuracy</b> in detecting anxiety.</p>
					</div>
					<br><br>

					<button class="container accordion">What can be concluded?</button>
					<div class="container panel">
					  	<p>In conclusion, the study proposed a <b>platform</b> and methodology for analysing human <b>physical and vocal activities</b> in association 
							with anxiety. It identified several activity and audio data features relevant to anxiety detection and implemented a <b>
								non-intrusive,
								 continuous data collection
							</b>method. Moreover, the study embedded speech feature <b>processing</b> algorithms into the wearable device, 
							 eliminating the need for raw speech data recording, thus avoiding options for <b>privacy violations</b> and the need for high data 
							 transmission.</p>
					</div>
					<br><br>

					<button class="accordion">Download</button>
					<div class="panel">
					  <p>Click <a href="pdfs/social.pdf" download>here</a>  to download the original paper.</p>
					</div>
					<br><br>

				</div>
			</div>

		<!-- Scripts -->
			<script src="assets/js/accordion.js"></script>
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
